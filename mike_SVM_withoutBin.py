# åŒ¯å…¥å¥—ä»¶
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE

from sklearn.svm import SVC


# ========== Step 1: è¼‰å…¥è³‡æ–™ ========== #
df_drug = pd.read_csv('drug200.csv')

# å‚™ä»½åŸå§‹ df 
df_drug_original = df_drug.copy()


# One-hot ç·¨ç¢¼ + åˆ†é¡
X = df_drug.drop(["Drug"], axis=1)
y = df_drug["Drug"]
X = pd.get_dummies(X)
X = X.astype(int)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# SMOTE éæ¡æ¨£
X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)

# ========== Step 2: SVC è¨“ç·´ ========== #
SVCclassifier = SVC(kernel='linear', max_iter=251)
SVCclassifier.fit(X_train, y_train)
y_pred_svc = SVCclassifier.predict(X_test)

print("ğŸ¯ å‚³çµ± SVC çµæœï¼š")
print(classification_report(y_test, y_pred_svc))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_svc))
print('SVC accuracy is: {:.2f}%'.format(accuracy_score(y_pred_svc, y_test) * 100))

# ========== æ©Ÿå™¨å­¸ç¿’æ–¹æ³•æ¯”è¼ƒ ========== #
print("\n" + "="*60)
print("ğŸ¤– å¤šç¨®æ©Ÿå™¨å­¸ç¿’æ–¹æ³•æ¯”è¼ƒ")
print("="*60)

# å°å…¥æ›´å¤šæ©Ÿå™¨å­¸ç¿’æ–¹æ³•
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
import time

# Initialize all classifiers with English names
classifiers = {
    'Linear SVM': SVC(kernel='linear', max_iter=251, random_state=42), # ä½¿ç”¨ç·šæ€§æ ¸çš„ SVM
    'RBF SVM': SVC(kernel='rbf', max_iter=251, random_state=42),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42), #   ä½¿ç”¨éš¨æ©Ÿæ£®æ—åˆ†é¡å™¨
    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),
    'Decision Tree': DecisionTreeClassifier(random_state=42), # ä½¿ç”¨æ±ºç­–æ¨¹åˆ†é¡å™¨
    'Naive Bayes': GaussianNB(),
    'Neural Network': MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42),
    'AdaBoost': AdaBoostClassifier(n_estimators=50, random_state=42)
}

# å„²å­˜çµæœ
results = {}

print("ğŸš€ é–‹å§‹è¨“ç·´å’Œè©•ä¼°å„ç¨®æ©Ÿå™¨å­¸ç¿’æ–¹æ³•...")
print("-" * 60)

for name, classifier in classifiers.items():
    print(f"æ­£åœ¨è¨“ç·´ {name}...")
    
    # è¨˜éŒ„è¨“ç·´æ™‚é–“
    start_time = time.time()
    classifier.fit(X_train, y_train)
    train_time = time.time() - start_time
    
    # é æ¸¬
    start_time = time.time()
    y_pred = classifier.predict(X_test)
    predict_time = time.time() - start_time
    
    # è¨ˆç®—æ€§èƒ½æŒ‡æ¨™
    accuracy = accuracy_score(y_test, y_pred)
    
    # å„²å­˜çµæœ
    results[name] = {
        'accuracy': accuracy,
        'train_time': train_time,
        'predict_time': predict_time,
        'predictions': y_pred
    }
    
    print(f"  âœ… {name} - æº–ç¢ºç‡: {accuracy:.4f} ({accuracy*100:.2f}%) | è¨“ç·´æ™‚é–“: {train_time:.3f}s")

# ========== çµæœæ¯”è¼ƒå’Œè¦–è¦ºåŒ– ========== #
print("\n" + "="*60)
print("ğŸ“Š è©³ç´°æ€§èƒ½æ¯”è¼ƒ")
print("="*60)

# å»ºç«‹æ¯”è¼ƒ DataFrame
comparison_data = []
for name, result in results.items():
    comparison_data.append({
        'æ–¹æ³•': name,
        'æº–ç¢ºç‡ (%)': f"{result['accuracy']*100:.2f}",
        'è¨“ç·´æ™‚é–“ (s)': f"{result['train_time']:.3f}",
        'é æ¸¬æ™‚é–“ (s)': f"{result['predict_time']:.3f}"
    })

comparison_df = pd.DataFrame(comparison_data)
comparison_df = comparison_df.sort_values('æº–ç¢ºç‡ (%)', ascending=False)

print("ğŸ† æŒ‰æº–ç¢ºç‡æ’åºçš„çµæœ:")
print(comparison_df.to_string(index=False))

# Set English font for matplotlib to avoid encoding issues
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

# Visualization comparison
fig, axes = plt.subplots(2, 2, figsize=(16, 12))
fig.suptitle('Machine Learning Methods Comprehensive Comparison', fontsize=16, fontweight='bold')

# 1. Accuracy comparison
methods = list(results.keys())
accuracies = [results[method]['accuracy'] for method in methods]

colors = plt.cm.viridis(np.linspace(0, 1, len(methods)))
bars1 = axes[0,0].bar(range(len(methods)), accuracies, color=colors)
axes[0,0].set_title('Accuracy Comparison')
axes[0,0].set_ylabel('Accuracy')
axes[0,0].set_xticks(range(len(methods)))
axes[0,0].set_xticklabels(methods, rotation=45, ha='right')
axes[0,0].set_ylim(0, 1)

# Add value labels
for bar, acc in zip(bars1, accuracies):
    height = bar.get_height()
    axes[0,0].text(bar.get_x() + bar.get_width()/2., height + 0.01,
                  f'{acc:.3f}', ha='center', va='bottom', fontsize=9)

# 2. Training time comparison
train_times = [results[method]['train_time'] for method in methods]
bars2 = axes[0,1].bar(range(len(methods)), train_times, color=colors)
axes[0,1].set_title('Training Time Comparison')
axes[0,1].set_ylabel('Training Time (seconds)')
axes[0,1].set_xticks(range(len(methods)))
axes[0,1].set_xticklabels(methods, rotation=45, ha='right')

# 3. Accuracy vs Speed scatter plot
predict_times = [results[method]['predict_time'] for method in methods]
scatter = axes[1,0].scatter(train_times, accuracies, 
                           c=range(len(methods)), cmap='viridis', s=100, alpha=0.7)
axes[1,0].set_xlabel('Training Time (seconds)')
axes[1,0].set_ylabel('Accuracy')
axes[1,0].set_title('Accuracy vs Training Speed')

# Add method labels
for i, method in enumerate(methods):
    axes[1,0].annotate(method, (train_times[i], accuracies[i]), 
                      xytext=(5, 5), textcoords='offset points', fontsize=8)

# 4. Best method confusion matrix
best_method = max(results.keys(), key=lambda x: results[x]['accuracy'])
best_predictions = results[best_method]['predictions']
cm = confusion_matrix(y_test, best_predictions)

# Get all drug categories
drug_labels = sorted(df_drug['Drug'].unique())
im = axes[1,1].imshow(cm, interpolation='nearest', cmap='Blues')
axes[1,1].set_title(f'Best Method Confusion Matrix\n({best_method})')

# Add text labels
thresh = cm.max() / 2.
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        axes[1,1].text(j, i, format(cm[i, j], 'd'),
                     ha="center", va="center",
                     color="white" if cm[i, j] > thresh else "black")

axes[1,1].set_xticks(range(len(drug_labels)))
axes[1,1].set_yticks(range(len(drug_labels)))
axes[1,1].set_xticklabels(drug_labels)
axes[1,1].set_yticklabels(drug_labels)
axes[1,1].set_xlabel('Predicted Labels')
axes[1,1].set_ylabel('True Labels')

plt.tight_layout()
plt.savefig('ml_methods_comparison_english.png', dpi=300, bbox_inches='tight')
plt.show()

# ========== è©³ç´°åˆ†æå ±å‘Š ========== #
print(f"\nğŸ“‹ æœ€ä½³æ–¹æ³•è©³ç´°å ±å‘Š ({best_method}):")
print("-" * 40)
best_accuracy = results[best_method]['accuracy']
print(f"æº–ç¢ºç‡: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)")
print(f"è¨“ç·´æ™‚é–“: {results[best_method]['train_time']:.3f} ç§’")
print(f"é æ¸¬æ™‚é–“: {results[best_method]['predict_time']:.3f} ç§’")
print("\nåˆ†é¡å ±å‘Š:")
print(classification_report(y_test, best_predictions))

# æ‰¾å‡ºæº–ç¢ºç‡å‰ä¸‰å
top3_methods = sorted(results.keys(), key=lambda x: results[x]['accuracy'], reverse=True)[:3]
print(f"\nğŸ† æº–ç¢ºç‡å‰ä¸‰å:")
for i, method in enumerate(top3_methods, 1):
    acc = results[method]['accuracy']
    print(f"  {i}. {method}: {acc:.4f} ({acc*100:.2f}%)")

# æ‰¾å‡ºé€Ÿåº¦æœ€å¿«çš„æ–¹æ³•
fastest_method = min(results.keys(), key=lambda x: results[x]['train_time'])
print(f"\nâš¡ è¨“ç·´é€Ÿåº¦æœ€å¿«: {fastest_method} ({results[fastest_method]['train_time']:.3f}s)")

print(f"\nğŸ’¾ æ¯”è¼ƒåœ–è¡¨å·²å„²å­˜è‡³ ml_methods_comparison.png")
print("ğŸ‰ æ©Ÿå™¨å­¸ç¿’æ–¹æ³•æ¯”è¼ƒå®Œæˆï¼")

